{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка Pandas и очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "from multiprocessing import  Pool\n",
    "from datetime import datetime, timedelta\n",
    "from collections import namedtuple, Counter\n",
    "from itertools import combinations\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this is just a file with a worker function for multiprocessing\n",
    "# (otherwise multiprocessing doesn't work in Jupyter on Windows)\n",
    "import worker  \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions are defined in this cell\n",
    "\n",
    "'''\n",
    "# These functions are in worker.py file now\n",
    "def from_website(url):\n",
    "    #print(f\"https://www.tripadvisor.com{url}\")\n",
    "    r = requests.get(f\"https://www.tripadvisor.com{url}\", timeout=2)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    \n",
    "    tmp = soup.find_all('span', {\"class\":\"ratingDate\"})\n",
    "    rev_dates_lst = [i['title'] for i in tmp]\n",
    "    #rev_dates_lst = [datetime.strptime(i['title'], '%B %d, %Y') for i in tmp]\n",
    "    \n",
    "    return rev_dates_lst\n",
    "\n",
    "\n",
    "def apply_to_dataframe(df):\n",
    "    df_result = df.copy()\n",
    "    df_result['all_review_dates'] = df_result['URL_TA'].apply(from_website)\n",
    "    return df_result\n",
    "'''\n",
    "\n",
    "def parallelize_dataframe(df, func, n_cores=30):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_freq_dict(d):\n",
    "    '''\n",
    "    Input dictionary must be sorted!\n",
    "    \n",
    "    This function takes dictionary with absolute frequencies as an argument\n",
    "    and converts it into dictionary with relative frequencies percentages.\n",
    "    \n",
    "    For example, dictionary {'$$$$': 1423, '$': 6279, '$$ - $$$': 18412}\n",
    "    will be turned into {'$$$$': 5.0, '$': 24.0, '$$ - $$$': 71.0}\n",
    "    '''\n",
    "    result = d\n",
    "    tot = np.sum(list(d.values()))\n",
    "    for k, v in d.items():\n",
    "        d[k] = round(int(v) / tot * 100,0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def fill_na_by_frequency(freq_dict, col):\n",
    "    '''\n",
    "    This function is used to replace NaN for categorical\n",
    "    columns with values based on the frequency of non-missing values.\n",
    "\n",
    "    For this function to work freq_dict (frequency dictionary) should be passed\n",
    "    as an arguemnt. That's how frequency dictionary might look like (just an example)\n",
    "    freq_dict: {'other': 7.0, 'father': 24.0, 'mother': 69.0}.\n",
    "    Numbers correspond to the frequency of every possible distinct value.\n",
    "\n",
    "    IMPORTANT: this function can't be applied using df.fillna() because the result\n",
    "    must be different for every row it applies to, whereas fillna() replaces all NaN\n",
    "    with a single value. Therefore apply() should be used on a column (series)\n",
    "    '''\n",
    "\n",
    "    rnd_check = round(random.random()*100)    \n",
    "    \n",
    "    cumulative = 0\n",
    "    for k, v in freq_dict.items():\n",
    "        # cumulative is used to correctly assess the probability\n",
    "        # for example, if we take {'other': 7.0, 'father': 24.0, 'mother': 69.0}\n",
    "        # then \"other\" will be picked is rnd_check if <= 7, \"father\" will be\n",
    "        # picked if rnd_check <= 31 and \"mother\" will be picked in al the other cases\n",
    "        cumulative += v\n",
    "        if rnd_check <= cumulative:\n",
    "            #print(f'Random number is: {rnd_check}. Value is: {k}')\n",
    "            return k\n",
    "    # the last option\n",
    "    return k\n",
    "    #print(f'Random number is: {rnd_check}. Value is: {k}')\n",
    "    \n",
    "    \n",
    "def convert_price_range(s):\n",
    "    '''\n",
    "    Converts price ranges provided as one of these values\n",
    "    $\n",
    "    $$ - $$$            \n",
    "    $$$$\n",
    "    to low, average and high \n",
    "    '''\n",
    "    if s == '$':\n",
    "        return 'low'\n",
    "    elif s == '$$ - $$$':\n",
    "        return 'average'\n",
    "    elif s == '$$$$':\n",
    "        return 'high'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "def median_interval(l):\n",
    "    '''\n",
    "    Takes a list with dates as strings in a format like 'February 28, 2017'\n",
    "    and returns a median interval between 2 consequent dates in a dataset\n",
    "    '''   \n",
    "    #tmp = ast.literal_eval(l)\n",
    "    tmp = l\n",
    "    res_lst = []\n",
    "    if len(tmp) > 1:\n",
    "        tmp = [datetime.strptime(i, '%B %d, %Y') for i in tmp]\n",
    "        i = 0\n",
    "        for d in tmp:\n",
    "            res_lst.append((tmp[i] - d).days)\n",
    "        return np.median(res_lst)\n",
    "    return -1\n",
    "\n",
    "def restaurant_age(l, snapshot_date):\n",
    "    '''\n",
    "    Takes a list with dates as strings in a format like 'February 28, 2017'\n",
    "    and returns a day difference between snapshot_date and the first review date\n",
    "    (let's  consider that an estimate of restaurant age on Tripadvisor website)\n",
    "    '''   \n",
    "    #tmp = ast.literal_eval(l)\n",
    "    tmp = l\n",
    "    res_lst = []\n",
    "    if len(tmp) > 0:\n",
    "        tmp = [datetime.strptime(i, '%B %d, %Y') for i in tmp]\n",
    "        return (snapshot_date - np.min(tmp)).days\n",
    "    return -1\n",
    "\n",
    "def is_weekend(l):\n",
    "    '''\n",
    "    Takes a list with dates as strings in a format like 'February 28, 2017'\n",
    "    and returns the most frequent weekday when the review was left\n",
    "    '''   \n",
    "    #tmp = ast.literal_eval(l)\n",
    "    tmp = l\n",
    "    res_lst = []\n",
    "    if len(tmp) > 0:\n",
    "        tmp = [datetime.strftime(datetime.strptime(i, '%B %d, %Y'),'%A') for i in tmp]\n",
    "        day = Counter(tmp).most_common(1)[0][0]\n",
    "        if day.lower() in ['saturday','sunday']:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1    \n",
    "    return -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Restaurant_id      40000 non-null  object \n",
      " 1   City               40000 non-null  object \n",
      " 2   Cuisine Style      30717 non-null  object \n",
      " 3   Ranking            40000 non-null  float64\n",
      " 4   Rating             40000 non-null  float64\n",
      " 5   Price Range        26114 non-null  object \n",
      " 6   Number of Reviews  37457 non-null  float64\n",
      " 7   Reviews            40000 non-null  object \n",
      " 8   URL_TA             40000 non-null  object \n",
      " 9   ID_TA              40000 non-null  object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('main_task.xls')\n",
    "df_small = df.iloc[:240,:] # I sometimes use it for testing\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>City</th>\n",
       "      <th>Cuisine Style</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price Range</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>URL_TA</th>\n",
       "      <th>ID_TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_5569</td>\n",
       "      <td>Paris</td>\n",
       "      <td>['European', 'French', 'International']</td>\n",
       "      <td>5570.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>194.0</td>\n",
       "      <td>[['Good food at your doorstep', 'A good hotel ...</td>\n",
       "      <td>/Restaurant_Review-g187147-d1912643-Reviews-R_...</td>\n",
       "      <td>d1912643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1535</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[['Unique cuisine', 'Delicious Nepalese food']...</td>\n",
       "      <td>/Restaurant_Review-g189852-d7992032-Reviews-Bu...</td>\n",
       "      <td>d7992032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_352</td>\n",
       "      <td>London</td>\n",
       "      <td>['Japanese', 'Sushi', 'Asian', 'Grill', 'Veget...</td>\n",
       "      <td>353.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>$$$$</td>\n",
       "      <td>688.0</td>\n",
       "      <td>[['Catch up with friends', 'Not exceptional'],...</td>\n",
       "      <td>/Restaurant_Review-g186338-d8632781-Reviews-RO...</td>\n",
       "      <td>d8632781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_3456</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3458.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>/Restaurant_Review-g187323-d1358776-Reviews-Es...</td>\n",
       "      <td>d1358776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_615</td>\n",
       "      <td>Munich</td>\n",
       "      <td>['German', 'Central European', 'Vegetarian Fri...</td>\n",
       "      <td>621.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>84.0</td>\n",
       "      <td>[['Best place to try a Bavarian food', 'Nice b...</td>\n",
       "      <td>/Restaurant_Review-g187309-d6864963-Reviews-Au...</td>\n",
       "      <td>d6864963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id_1418</td>\n",
       "      <td>Oporto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[['There are better 3 star hotel bars', 'Amazi...</td>\n",
       "      <td>/Restaurant_Review-g189180-d12503536-Reviews-D...</td>\n",
       "      <td>d12503536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id_1720</td>\n",
       "      <td>Milan</td>\n",
       "      <td>['Italian', 'Pizza']</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>$</td>\n",
       "      <td>50.0</td>\n",
       "      <td>[['Excellent simple local eatery.', 'Excellent...</td>\n",
       "      <td>/Restaurant_Review-g187849-d5808504-Reviews-Pi...</td>\n",
       "      <td>d5808504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id_825</td>\n",
       "      <td>Bratislava</td>\n",
       "      <td>['Italian']</td>\n",
       "      <td>826.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[['Wasting of money', 'excellent cuisine'], ['...</td>\n",
       "      <td>/Restaurant_Review-g274924-d3199765-Reviews-Ri...</td>\n",
       "      <td>d3199765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id_2690</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2692.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>/Restaurant_Review-g190454-d12845029-Reviews-G...</td>\n",
       "      <td>d12845029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id_4209</td>\n",
       "      <td>Rome</td>\n",
       "      <td>['Italian', 'Pizza', 'Fast Food']</td>\n",
       "      <td>4210.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>$</td>\n",
       "      <td>55.0</td>\n",
       "      <td>[['Clean efficient staff', 'Nice little pizza ...</td>\n",
       "      <td>/Restaurant_Review-g187791-d8020681-Reviews-Qu...</td>\n",
       "      <td>d8020681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Restaurant_id        City  \\\n",
       "0       id_5569       Paris   \n",
       "1       id_1535   Stockholm   \n",
       "2        id_352      London   \n",
       "3       id_3456      Berlin   \n",
       "4        id_615      Munich   \n",
       "5       id_1418      Oporto   \n",
       "6       id_1720       Milan   \n",
       "7        id_825  Bratislava   \n",
       "8       id_2690      Vienna   \n",
       "9       id_4209        Rome   \n",
       "\n",
       "                                       Cuisine Style  Ranking  Rating  \\\n",
       "0            ['European', 'French', 'International']   5570.0     3.5   \n",
       "1                                                NaN   1537.0     4.0   \n",
       "2  ['Japanese', 'Sushi', 'Asian', 'Grill', 'Veget...    353.0     4.5   \n",
       "3                                                NaN   3458.0     5.0   \n",
       "4  ['German', 'Central European', 'Vegetarian Fri...    621.0     4.0   \n",
       "5                                                NaN   1419.0     3.0   \n",
       "6                               ['Italian', 'Pizza']   1722.0     4.0   \n",
       "7                                        ['Italian']    826.0     3.0   \n",
       "8                                                NaN   2692.0     4.0   \n",
       "9                  ['Italian', 'Pizza', 'Fast Food']   4210.0     4.0   \n",
       "\n",
       "  Price Range  Number of Reviews  \\\n",
       "0    $$ - $$$              194.0   \n",
       "1         NaN               10.0   \n",
       "2        $$$$              688.0   \n",
       "3         NaN                3.0   \n",
       "4    $$ - $$$               84.0   \n",
       "5         NaN                2.0   \n",
       "6           $               50.0   \n",
       "7         NaN                9.0   \n",
       "8         NaN                NaN   \n",
       "9           $               55.0   \n",
       "\n",
       "                                             Reviews  \\\n",
       "0  [['Good food at your doorstep', 'A good hotel ...   \n",
       "1  [['Unique cuisine', 'Delicious Nepalese food']...   \n",
       "2  [['Catch up with friends', 'Not exceptional'],...   \n",
       "3                                           [[], []]   \n",
       "4  [['Best place to try a Bavarian food', 'Nice b...   \n",
       "5  [['There are better 3 star hotel bars', 'Amazi...   \n",
       "6  [['Excellent simple local eatery.', 'Excellent...   \n",
       "7  [['Wasting of money', 'excellent cuisine'], ['...   \n",
       "8                                           [[], []]   \n",
       "9  [['Clean efficient staff', 'Nice little pizza ...   \n",
       "\n",
       "                                              URL_TA      ID_TA  \n",
       "0  /Restaurant_Review-g187147-d1912643-Reviews-R_...   d1912643  \n",
       "1  /Restaurant_Review-g189852-d7992032-Reviews-Bu...   d7992032  \n",
       "2  /Restaurant_Review-g186338-d8632781-Reviews-RO...   d8632781  \n",
       "3  /Restaurant_Review-g187323-d1358776-Reviews-Es...   d1358776  \n",
       "4  /Restaurant_Review-g187309-d6864963-Reviews-Au...   d6864963  \n",
       "5  /Restaurant_Review-g189180-d12503536-Reviews-D...  d12503536  \n",
       "6  /Restaurant_Review-g187849-d5808504-Reviews-Pi...   d5808504  \n",
       "7  /Restaurant_Review-g274924-d3199765-Reviews-Ri...   d3199765  \n",
       "8  /Restaurant_Review-g190454-d12845029-Reviews-G...  d12845029  \n",
       "9  /Restaurant_Review-g187791-d8020681-Reviews-Qu...   d8020681  "
      ]
     },
     "execution_count": 1111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>City</th>\n",
       "      <th>Cuisine Style</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price Range</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>URL_TA</th>\n",
       "      <th>ID_TA</th>\n",
       "      <th>all_review_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_5569</td>\n",
       "      <td>Paris</td>\n",
       "      <td>['European', 'French', 'International']</td>\n",
       "      <td>5570.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>194.0</td>\n",
       "      <td>[['Good food at your doorstep', 'A good hotel ...</td>\n",
       "      <td>/Restaurant_Review-g187147-d1912643-Reviews-R_...</td>\n",
       "      <td>d1912643</td>\n",
       "      <td>['February 14, 2020', 'December 20, 2019', 'No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1535</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[['Unique cuisine', 'Delicious Nepalese food']...</td>\n",
       "      <td>/Restaurant_Review-g189852-d7992032-Reviews-Bu...</td>\n",
       "      <td>d7992032</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_352</td>\n",
       "      <td>London</td>\n",
       "      <td>['Japanese', 'Sushi', 'Asian', 'Grill', 'Veget...</td>\n",
       "      <td>353.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>$$$$</td>\n",
       "      <td>688.0</td>\n",
       "      <td>[['Catch up with friends', 'Not exceptional'],...</td>\n",
       "      <td>/Restaurant_Review-g186338-d8632781-Reviews-RO...</td>\n",
       "      <td>d8632781</td>\n",
       "      <td>['September 25, 2020', 'September 5, 2020', 'A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_3456</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3458.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>/Restaurant_Review-g187323-d1358776-Reviews-Es...</td>\n",
       "      <td>d1358776</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_615</td>\n",
       "      <td>Munich</td>\n",
       "      <td>['German', 'Central European', 'Vegetarian Fri...</td>\n",
       "      <td>621.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>84.0</td>\n",
       "      <td>[['Best place to try a Bavarian food', 'Nice b...</td>\n",
       "      <td>/Restaurant_Review-g187309-d6864963-Reviews-Au...</td>\n",
       "      <td>d6864963</td>\n",
       "      <td>['September 10, 2020', 'September 28, 2019', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Restaurant_id       City                                      Cuisine Style  \\\n",
       "0       id_5569      Paris            ['European', 'French', 'International']   \n",
       "1       id_1535  Stockholm                                                NaN   \n",
       "2        id_352     London  ['Japanese', 'Sushi', 'Asian', 'Grill', 'Veget...   \n",
       "3       id_3456     Berlin                                                NaN   \n",
       "4        id_615     Munich  ['German', 'Central European', 'Vegetarian Fri...   \n",
       "\n",
       "   Ranking  Rating Price Range  Number of Reviews  \\\n",
       "0   5570.0     3.5    $$ - $$$              194.0   \n",
       "1   1537.0     4.0         NaN               10.0   \n",
       "2    353.0     4.5        $$$$              688.0   \n",
       "3   3458.0     5.0         NaN                3.0   \n",
       "4    621.0     4.0    $$ - $$$               84.0   \n",
       "\n",
       "                                             Reviews  \\\n",
       "0  [['Good food at your doorstep', 'A good hotel ...   \n",
       "1  [['Unique cuisine', 'Delicious Nepalese food']...   \n",
       "2  [['Catch up with friends', 'Not exceptional'],...   \n",
       "3                                           [[], []]   \n",
       "4  [['Best place to try a Bavarian food', 'Nice b...   \n",
       "\n",
       "                                              URL_TA     ID_TA  \\\n",
       "0  /Restaurant_Review-g187147-d1912643-Reviews-R_...  d1912643   \n",
       "1  /Restaurant_Review-g189852-d7992032-Reviews-Bu...  d7992032   \n",
       "2  /Restaurant_Review-g186338-d8632781-Reviews-RO...  d8632781   \n",
       "3  /Restaurant_Review-g187323-d1358776-Reviews-Es...  d1358776   \n",
       "4  /Restaurant_Review-g187309-d6864963-Reviews-Au...  d6864963   \n",
       "\n",
       "                                    all_review_dates  \n",
       "0  ['February 14, 2020', 'December 20, 2019', 'No...  \n",
       "1                                                 []  \n",
       "2  ['September 25, 2020', 'September 5, 2020', 'A...  \n",
       "3                                                 []  \n",
       "4  ['September 10, 2020', 'September 28, 2019', '...  "
      ]
     },
     "execution_count": 1112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Uncomment it only if you need to crawl Tripadvisor website once again\n",
    "# Please note that it takes around 2-3 hours (depending on the machine)\n",
    "# to perform the crawling\n",
    "if __name__ ==  '__main__': \n",
    "    df_crawled = parallelize_dataframe(df, worker.apply_to_dataframe)\n",
    "    \n",
    "df_crawled.to_csv('with_additional_data_from_TA_ALL_2.csv')    \n",
    "'''\n",
    "\n",
    "# this is a file that consists of an original dataframe \n",
    "# extended with additional data from Tripadvisor website\n",
    "# using requests and beautifulsoup\n",
    "df = pd.read_csv('with_additional_data_from_TA_ALL_2.csv')\n",
    "df.drop(labels=['Unnamed: 0'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot date: 2018-02-26 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Given the fact that it's currently year 2020 and a dataset for the task contains\n",
    "# an older data it would be wise to avoid using records that appeared after a maximal\n",
    "# date available in this dataset (the ones I obtained using web crawling).\n",
    "# Let's find this date\n",
    "df['tst'] = df['Reviews'].map(lambda x: x.split(\"], [\")[1])\n",
    "df['tst'] = df['tst'].str.replace('[','').str.replace(']','').str.replace(\"'\",'').str.replace(\"'\",'').str.split(',')\n",
    "task_snapshot_date = pd.to_datetime(df['tst'].explode()).max()\n",
    "df.drop(labels=['tst'], axis=1, inplace=True)\n",
    "print(f\"Snapshot date: {task_snapshot_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data was saved to a file after web crawler (function from_website) was executed.\n",
    "# It means that all_review_dates contains a string representation of a list.\n",
    "# Let's convert it into the list to make other functions run faster\n",
    "df['all_review_dates'] = df['all_review_dates'].map(ast.literal_eval)\n",
    "\n",
    "# Let's remove all the review dates after task_snapshot_date\n",
    "df['all_review_dates'] = df['all_review_dates'].map(lambda lst:\\\n",
    "    [i for i in lst if task_snapshot_date >= datetime.strptime(i, '%B %d, %Y')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop Restaurant_id, ID_TA and URL_TA because we don't need them anymore\n",
    "df.drop(labels=['Restaurant_id', 'ID_TA','URL_TA'], axis=1, inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create 2 simple columns to mimic a basic sentiment analysis\n",
    "# first column will be 1 if a restaurant contains some negative review\n",
    "# (like bad, awful, horrible, dirty, disgusting) in 2 reviews provided\n",
    "# in a dataset\n",
    "bad_words = \"terrible|very bad|awful|horrible|dirty|disgusting|bad experience|don't go|bad service|unfriendly|not good|\"\\\n",
    "    \"disappointed|rubbish|average food|bad customer service|poor\"\n",
    "df['contains_bad_review'] = df['Reviews'].str.contains(bad_words, regex=True, case=False).astype(int)\n",
    "\n",
    "# same but with good words \n",
    "good_words = \"good|nice|amazing|best|great|excellent\"\n",
    "df['contains_good_review'] = df['Reviews'].str.contains(good_words, regex=True, case=False).astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['contains_bad_review','contains_good_review']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some cases when no reviews are given in a list - let's mark them\n",
    "df['no_reviews_in_list'] = (df['Reviews'] == \"[[], []]\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's process dates available in 'Reviews' column\n",
    "df['tst'] = df['Reviews'].map(lambda x: x.split(\"], [\"))\n",
    "df['dates'] = df['tst'].map(lambda x : x[1]).str.replace('[','').str.replace(']','').str.replace(\"'\",'').str.split(',')\n",
    "df['dates'] = df['dates'].map(lambda x: x if len(x) < 2 else [datetime.strptime(i.strip(), '%m/%d/%Y') for i in x])\n",
    "# let's create a variable that stores number of days since TripAdvisor website creation (2004-02-01) up to the most recent comment\n",
    "# if there's no  date available - mark this column as -1\n",
    "df['days_since_ta_creation'] = df['dates'].map(lambda x : -1 if len(x) < 2 else (max(x) - datetime.strptime('2004-02-01', '%Y-%m-%d')).days)\n",
    "# let's create a variable that stores days between comments\n",
    "df['days_between_comments'] = df['dates'].map(lambda x : -1 if len(x) < 2 else (x[0] - x[1]).days)\n",
    "df.drop(labels=['tst','dates'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining unique cuisine styles and their value counts\n",
    "# ast.literal_eval is required because lists of styles are\n",
    "# represented as strings in the dataframe\n",
    "# IMPORTANT: nan values are replaced by the fake list empty list \"[]\" for this\n",
    "# particular part of the task, but that does not happen in place\n",
    "df['cuisine_styles_num'] = df['Cuisine Style'].fillna(\"[]\").apply(ast.literal_eval).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the number of unique cuisine styles (empty records will be marked as\n",
    "# a \"no_style_provided\" in place)\n",
    "df['Cuisine Style'].fillna(\"['no_style_provided']\", inplace=True)\n",
    "\n",
    "unique_styles = df['Cuisine Style'].apply(ast.literal_eval).explode()\\\n",
    "    .value_counts(normalize=True)\n",
    "\n",
    "sum(unique_styles.head(25)), unique_styles.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take top 25 styles and create binary variables out of them\n",
    "# (for example, European can be either 0 or 1).\n",
    "for c in list(unique_styles.head(25).index):\n",
    "    df[c] = df['Cuisine Style'].str.contains(c, regex=False).astype(int)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's consider NaN in number of reviews as 0\n",
    "df['Number of Reviews'].fillna(0, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['City'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use worldcities dataset from https://www.kaggle.com/viswanathanc/world-cities-datasets\n",
    "# I want to create 2 dimension from an original 'City' column: capital and  population\n",
    "df_cities = pd.read_csv('worldcities.csv')\n",
    "\n",
    "# leaving only required columns from worldcities data set\n",
    "df_cities = df_cities[['city_ascii','capital','population']]\n",
    "\n",
    "# the assumption here is that most of the capitals will be listed as primary\n",
    "# and we don't really care about other classification because the variable will be\n",
    "# binary in the end (capital = 0 or 1)\n",
    "df_cities['capital'].fillna('other', inplace=True) \n",
    "\n",
    "# the assumption here is that most important cities will have the population\n",
    "# mentioned in the data set\n",
    "df_cities['population'].fillna(0, inplace=True)\n",
    "\n",
    "# leaving only cities with max population - this will eliminate duplicates\n",
    "# in case multiple cities with the same name exist\n",
    "df_cities.sort_values(by=['city_ascii','population'], ascending=[True,False], inplace=True)\n",
    "df_cities.drop_duplicates(subset='city_ascii', keep='first', inplace=True)\n",
    "\n",
    "# making sure we have no more duplicates\n",
    "df_cities['city_ascii'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying 'capital' column to make it binary (if capital then 1 else 0)\n",
    "df_cities['capital'] = df_cities['capital'].map(lambda x : 1 if x == 'primary' else 0)\n",
    "df_cities['capital'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging df with df_cities based on city name\n",
    "df = df.merge(df_cities, how='left', left_on='City', right_on='city_ascii')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see what cities are missing\n",
    "df[df['capital'].isna()]['City'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems that we're missing the data about only one city - Oporto (aka Porto in Portugal)\n",
    "# let's locate it and populate missing values manually\n",
    "df['capital'].fillna(0, inplace=True)\n",
    "df['population'].fillna(1337000, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's encode cities\n",
    "df['City_copy'] = df['City']\n",
    "df = pd.get_dummies(df, columns=[ 'City_copy',], dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop some columns that are not required anymore\n",
    "# to make the dataframe more compact and readable\n",
    "df.drop(['city_ascii', 'Cuisine Style', 'Reviews'], axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at price ranges\n",
    "df['Price Range'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems there are many NaN values among price ranges\n",
    "# let's replace NaN with values based on a frequency of the existing values\n",
    "# custom function will be used for that (see definition of helper functions above)\n",
    "\n",
    "# please note that ascending=True is important here because the dictionary must be sorted\n",
    "freq_dict = create_freq_dict(dict(df['Price Range'].value_counts(ascending=True)))\n",
    "df['Price Range'] = df['Price Range'].apply(\n",
    "    lambda x: fill_na_by_frequency(freq_dict, \"Price Range\") if pd.isna(x) else x)\n",
    "# also let's make Price Range names more meaningful (before we one hot encode them)\n",
    "df['Price Range'] = df['Price Range'].apply(convert_price_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at price ranges once again - it seems that there are\n",
    "# no more missing values\n",
    "df['Price Range'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and there are no more missing values in the dataframe as such\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing Price Range with one hot encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y = OneHotEncoder().fit_transform(df['Price Range'].to_numpy().reshape(-1, 1)).toarray()\n",
    "# list(df['Price Range'].unique()) is safe because the values are provided \n",
    "# in order of appearance\n",
    "df_price_rng = pd.DataFrame(y, columns=list(df['Price Range'].unique()))\n",
    "df = pd.concat([df,df_price_rng], axis=1)\n",
    "df.drop(['Price Range'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's calculate restaurant_age for every restaraunt and drop 'all_review_dates' column\n",
    "df['restaurant_age'] = df['all_review_dates'].map(lambda x: restaurant_age(x, snapshot_date=task_snapshot_date))\n",
    "# let's calculate median interval between consequetive review dates\n",
    "df['median_interval'] = df['all_review_dates'].map(median_interval)\n",
    "# let's determine if most reviews were left on weekend or a weekday\n",
    "df['is_weekend'] = df['all_review_dates'].map(is_weekend)\n",
    "df.drop(labels=['all_review_dates'], axis=1, inplace=True)\n",
    "df.info()\n",
    "print(f\"Most popular restaurant age on a tripadvisor: {df['restaurant_age'].value_counts().index[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual assessment of numeric variables\n",
    "for x in (df['City'].value_counts())[0:10].index:\n",
    "    df['Ranking'][df['City'] == x].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a variable that shows if restaraunt is above or below the average Ranking in the city\n",
    "df['avg_rank_by_city'] = df.groupby('City')['Ranking'].transform(np.mean)\n",
    "df['better_than_average'] = (df['Ranking'] < df['avg_rank_by_city']).astype(int)\n",
    "\n",
    "# let's normalize Ranking using count of restaurants in the city\n",
    "df['cnt_rest_in_the_city'] = df.groupby('City')['City'].transform('count')\n",
    "df['ranking_norm'] = df['Ranking']/df['cnt_rest_in_the_city']\n",
    "\n",
    "# let's normalize Ranking using max rank by city\n",
    "df['max_rank_by_city'] = df.groupby('City')['Ranking'].transform(np.max)\n",
    "df['ranking_norm_max'] = df['Ranking']/df['max_rank_by_city']\n",
    "\n",
    "# let's normalize Ranking using count of reviews by city\n",
    "df['cnt_rev_by_city'] = df.groupby('City')['Number of Reviews'].transform('sum')\n",
    "df['ranking_norm_reviews'] = df['Ranking']/df['cnt_rev_by_city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in (df['City'].value_counts())[0:10].index:\n",
    "    df['ranking_norm'][df['City'] == x].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in (df['City'].value_counts())[0:10].index:\n",
    "    df['ranking_norm_max'][df['City'] == x].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in (df['City'].value_counts())[0:10].index:\n",
    "    df['ranking_norm_reviews'][df['City'] == x].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a variable that shows number of reviews per 1000 citizens\n",
    "df['reviews_per_capita'] = df['Number of Reviews']*1000 / df['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['City', 'avg_rank_by_city', 'cnt_rest_in_the_city', 'cnt_rev_by_city', 'max_rank_by_city'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разбиваем датафрейм на части, необходимые для обучения и тестирования модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Х - данные с информацией о ресторанах, у - целевая переменная (рейтинги ресторанов)\n",
    "#X = df.drop(['Restaurant_id', 'Rating'], axis = 1)\n",
    "X = df.drop(['Rating'], axis = 1)\n",
    "y = df['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем специальный инструмент для разбивки:\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наборы данных с меткой \"train\" будут использоваться для обучения модели, \"test\" - для тестирования.\n",
    "# Для тестирования мы будем использовать 25% от исходного датасета.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаём, обучаем и тестируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель\n",
    "regr = RandomForestRegressor(n_estimators=100, random_state=RANDOM_SEED)\n",
    "\n",
    "# Обучаем модель на тестовом наборе данных\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
